# -*- coding: utf-8 -*-
"""diabetes_binary_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jHS029fSdbLVC0Dz92WQ0NGegXbgkCHD
"""



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import joblib

# Load the Pima Indians Diabetes dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=column_names)

# 1. Explore data
print("Dataset Shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())
print("\nData Summary:")
print(df.describe())
print("\nTarget Distribution:")
print(df['Outcome'].value_counts())

# Check for missing values (zeros in some columns represent missing values)
print("\nMissing Values (zeros):")
for column in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
    print(f"{column}: {(df[column] == 0).sum()} zeros")

# 2. Data Preprocessing
# Replace zeros with NaN and then fill with median
for column in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
    df[column] = df[column].replace(0, np.nan)
    df[column] = df[column].fillna(df[column].median())

# Split features and target
X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Create train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Model Training
# Function to evaluate models
def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)

    print(f"\n{model_name} Results:")
    print(f"Accuracy: {accuracy:.4f}")
    print("\nConfusion Matrix:")
    print(confusion_matrix(y_test, y_pred))
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # For models that can return probability scores
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test)[:, 1]

        # ROC Curve
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc = auc(fpr, tpr)

        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'ROC Curve - {model_name}')
        plt.legend(loc="lower right")
        plt.savefig(f"{model_name.replace(' ', '_')}_roc.png")
        plt.close()

        return accuracy, roc_auc

    return accuracy, None

# Train multiple models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42)
}

results = {}
for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    accuracy, roc_auc = evaluate_model(model, X_test_scaled, y_test, name)
    results[name] = {'model': model, 'accuracy': accuracy, 'roc_auc': roc_auc}

# 4. Feature Importance (for Random Forest)
rf_model = results['Random Forest']['model']
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Feature Importance (Random Forest)')
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.close()

# 5. Hyperparameter Tuning for the best model
# Determine best model (using ROC AUC if available, otherwise accuracy)
best_model_name = max(results.items(), key=lambda x: x[1]['roc_auc'] if x[1]['roc_auc'] else x[1]['accuracy'])[0]
print(f"\nBest model based on ROC AUC: {best_model_name}")

# Hyperparameter tuning
if best_model_name == 'Logistic Regression':
    param_grid = {
        'C': [0.01, 0.1, 1, 10, 100],
        'solver': ['liblinear', 'lbfgs', 'saga'],
        'penalty': ['l1', 'l2']
    }
    base_model = LogisticRegression(max_iter=1000, random_state=42)
elif best_model_name == 'Decision Tree':
    param_grid = {
        'max_depth': [None, 5, 10, 15, 20],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    base_model = DecisionTreeClassifier(random_state=42)
elif best_model_name == 'Random Forest':
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    base_model = RandomForestClassifier(random_state=42)
else:  # SVM
    param_grid = {
        'C': [0.1, 1, 10, 100],
        'gamma': ['scale', 'auto', 0.01, 0.1],
        'kernel': ['rbf', 'linear']
    }
    base_model = SVC(probability=True, random_state=42)

print(f"\nTuning hyperparameters for {best_model_name}...")
grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='roc_auc')
grid_search.fit(X_train_scaled, y_train)

print("Best parameters:", grid_search.best_params_)
print("Best cross-validation score:", grid_search.best_score_)

# 6. Final Evaluation with tuned model
best_tuned_model = grid_search.best_estimator_
evaluate_model(best_tuned_model, X_test_scaled, y_test, f"Tuned {best_model_name}")

# 7. Save the final model
joblib.dump(best_tuned_model, 'diabetes_classifier.pkl')
joblib.dump(scaler, 'diabetes_scaler.pkl')

# 8. Function to make new predictions
def predict_diabetes(model, scaler, new_data):
    """
    Predict diabetes for new patient data

    Parameters:
    - new_data: DataFrame with the same features as the training data
    - model: Trained model
    - scaler: Fitted scaler

    Returns:
    - Prediction (0 or 1) and probability
    """
    # Scale the data
    new_data_scaled = scaler.transform(new_data)

    # Make prediction
    prediction = model.predict(new_data_scaled)[0]
    probability = model.predict_proba(new_data_scaled)[0][1]

    return prediction, probability

# Example use
print("\nExample prediction for a new patient:")
new_patient = pd.DataFrame([[6, 148, 72, 35, 0, 33.6, 0.627, 50]],
                          columns=X.columns)
prediction, probability = predict_diabetes(best_tuned_model, scaler, new_patient)
print(f"Prediction: {'Diabetic' if prediction == 1 else 'Non-diabetic'}")
print(f"Probability of diabetes: {probability:.2f}")

